{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import timeit\n",
    "import torch\n",
    "import pprint\n",
    "import pathlib\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import albumentations\n",
    "from tqdm import tqdm\n",
    "from models.hrnet import HRNet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from utils.transformations import re_normalize\n",
    "from utils.modelsummary import get_model_summary\n",
    "from utils.runners import train, validate, testval, testvideo\n",
    "from utils.data_utils import get_labels, label_mapping, SegmentationDataset, display\n",
    "from utils.train_utils import AverageMeter, CrossEntropy, get_confusion_matrix, create_logger\n",
    "from utils.transformation_pipelines import (get_transforms_training, get_transforms_validation, \n",
    "                                            get_transforms_evaluation, get_transforms_video)\n",
    "from configs.hrnet_config import config as cfg\n",
    "\n",
    "labels = get_labels()\n",
    "id2label =      { label.id      : label for label in labels }\n",
    "trainid2label = { label.trainId : label for label in labels }\n",
    "\n",
    "def cityscapes_label_to_rgb(mask):\n",
    "    h = mask.shape[0]\n",
    "    w = mask.shape[1]\n",
    "    mask_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for key, val in trainid2label.items():\n",
    "        indices = mask == key\n",
    "        mask_rgb[indices.squeeze()] = val.color \n",
    "    return mask_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'cityscapes_dir': 'data/cityscapes',\n",
    "    'trainval_input_pattern': '*_leftImg8bit.png',\n",
    "    'trainval_annot_pattern': '*_gtFine_labelIds.png',\n",
    "    'trainval_image_dir': 'leftImg8bit',\n",
    "    'trainval_label_dir': 'gtFine',\n",
    "    \n",
    "    'DATASET': 'cityscapes',\n",
    "    'MODEL_NAME': 'seg_hrnet_w48',\n",
    "    'OUTPUT_DIR': 'outputs',\n",
    "    'LOG_DIR': 'logs',\n",
    "    \n",
    "    'CROP_SIZE': (512, 1024),\n",
    "    'BASE_SIZE': (1024, 2048),\n",
    "    'DATASET_MEAN': [0.485, 0.456, 0.406],\n",
    "    'DATASET_STD': [0.229, 0.224, 0.225],\n",
    "    'EPOCHS': 484,\n",
    "    'BATCH_SIZE': 12, \n",
    "    'NUM_CLASSES': 19,\n",
    "    'IGNORE_LABEL': 255,\n",
    "    'NUM_OUTPUTS': 1,\n",
    "    'BASE_LR': 1e-2,\n",
    "    'END_LR': 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc649f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_training = get_transforms_training(config)\n",
    "transforms_validation = get_transforms_validation(config)\n",
    "transforms_evaluation = get_transforms_evaluation(config)\n",
    "transforms_video = get_transforms_video(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ce1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(cfg = cfg, split = \"train\", transform = transforms_training)\n",
    "valid_dataset = SegmentationDataset(cfg = cfg, split = \"val\", transform = transforms_validation)\n",
    "eval_dataset = SegmentationDataset(cfg = cfg, split = \"val\", transform = transforms_evaluation)\n",
    "video_dataset = SegmentationDataset(cfg = cfg, split = \"demoVideo\", transform = transforms_video, labels=False)\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = cfg.TRAIN.BATCH_SIZE, \n",
    "                              shuffle = True, num_workers = 0)\n",
    "\n",
    "valid_dataloader = DataLoader(dataset = valid_dataset, batch_size = cfg.TRAIN.BATCH_SIZE, \n",
    "                              shuffle = True, num_workers = 0)\n",
    "\n",
    "eval_dataloader = DataLoader(dataset = eval_dataset, batch_size = 1, \n",
    "                             shuffle = False, num_workers = 0)\n",
    "\n",
    "video_dataloader = DataLoader(dataset = video_dataset, batch_size = 1, \n",
    "                              shuffle = False, num_workers = 0)\n",
    "\n",
    "x, y, _, names = next(iter(train_dataloader))\n",
    "xv, yv, _, vnames = next(iter(valid_dataloader))\n",
    "xt, yt, _, tnames = next(iter(eval_dataloader))\n",
    "xvd, _, tnames = next(iter(video_dataloader))\n",
    "\n",
    "x_min, x_max = x.min(), x.max()\n",
    "print('x.shape: {}, x.type: {}, [min(x), max(x)]: [{:.3f}, {:.3f}]'.format(x.numpy().shape, x.dtype, x_min, x_max))\n",
    "print('y.shape: {}, y.type: {} \\ny unique: {}'.format(y.numpy().shape, y.dtype, np.unique(y.numpy()).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba023148",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "display([re_normalize(x[idx].permute(1,2,0).numpy()), cityscapes_label_to_rgb(y[idx])])\n",
    "display([re_normalize(xv[idx].permute(1,2,0).numpy()), cityscapes_label_to_rgb(yv[idx])])\n",
    "display([re_normalize(xt[idx].permute(1,2,0).numpy()), cityscapes_label_to_rgb(yt[idx])])\n",
    "display([re_normalize(xvd[idx].permute(1,2,0).numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb611bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = HRNet(\n",
    "    stage1_cfg = {'NUM_MODULES': 1,'NUM_BRANCHES': 1,'BLOCK': 'BOTTLENECK','NUM_BLOCKS': [4]}, \n",
    "    stage2_cfg = {'NUM_MODULES': 1,'NUM_BRANCHES': 2,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4]},\n",
    "    stage3_cfg = {'NUM_MODULES': 4,'NUM_BRANCHES': 3,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4, 4]},\n",
    "    stage4_cfg = {'NUM_MODULES': 3,'NUM_BRANCHES': 4,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4, 4, 4]},\n",
    "    n_classes = config['NUM_CLASSES'], \n",
    "    input_height = 512, \n",
    "    input_width = 1024, \n",
    "    W = 48,\n",
    ").to(device)\n",
    "\n",
    "criterion = CrossEntropy(\n",
    "    ignore_label=cfg.DATASET.IGNORE_LABEL, \n",
    "    weight=train_dataset.class_weights\n",
    ")#.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=cfg.TRAIN.BASE_LR, \n",
    "    momentum=cfg.TRAIN.MOMENTUM, \n",
    "    weight_decay=cfg.TRAIN.WD\n",
    ")\n",
    "\n",
    "# model.init_weights(pretrained = cfg.MODEL.PRETRAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344dab6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"weights/hrnet_w48.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# checkpoint = torch.load(\"weights/hrnet_w48.pth.tar\", map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046db724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_loop():\n",
    "    \n",
    "    logger, final_output_dir, tb_log_dir = create_logger(\n",
    "        config, \n",
    "        cfg_name=\"seg_hrnet_w48_train_512x1024_sgd_lr1e-2_wd5e-4_bs_12_epoch484\", \n",
    "        phase='train'\n",
    "    )\n",
    "    \n",
    "    # dump_input = torch.rand((1, 3, 512, 1024))\n",
    "    # logger.info(get_model_summary(model.cuda(), dump_input.cuda()))\n",
    "\n",
    "    writer_dict = {\n",
    "        'writer': SummaryWriter(tb_log_dir),\n",
    "        'train_global_steps': 0,\n",
    "        'valid_global_steps': 0,\n",
    "    }\n",
    "\n",
    "    best_mIoU = 0\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    for epoch in range(cfg.TRAIN.EPOCHS):\n",
    "\n",
    "        train(\n",
    "            config=config, \n",
    "            dataloader=train_dataloader, \n",
    "            model=model, \n",
    "            loss_fn=criterion, \n",
    "            optimizer=optimizer, \n",
    "            epoch=epoch, \n",
    "            scaler=torch.cuda.amp.GradScaler(),\n",
    "            writer_dict=writer_dict\n",
    "        )\n",
    "\n",
    "        valid_loss, mean_IoU, IoU_array = validate(\n",
    "            config=config, \n",
    "            dataloader=valid_dataloader, \n",
    "            model=model,  \n",
    "            loss_fn=criterion,\n",
    "            writer_dict=writer_dict\n",
    "        )\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'best_mIoU': best_mIoU,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, os.path.join(final_output_dir,'checkpoint.pth.tar'))\n",
    "\n",
    "        if mean_IoU > best_mIoU:\n",
    "            best_mIoU = mean_IoU\n",
    "            torch.save(model.state_dict(), os.path.join(final_output_dir, 'best.pth'))\n",
    "\n",
    "        msg = 'Epoch {}/{} --- Loss: {:.3f}, MeanIU: {: 4.4f}, Best_mIoU: {: 4.4f} \\n'.format(\n",
    "            epoch+1, cfg.TRAIN.EPOCHS, valid_loss, mean_IoU, best_mIoU)\n",
    "        logging.info(msg)\n",
    "        \n",
    "    torch.save(model.state_dict(), os.path.join(final_output_dir, 'final_state.pth'))\n",
    "\n",
    "    writer_dict['writer'].close()\n",
    "    end = timeit.default_timer()\n",
    "    logger.info('Hours: %d' % np.int((end-start)/3600))\n",
    "    logger.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec33269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214483a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "testvideo(config, video_dataloader, model, sv_dir='outputs', sv_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_IoU, IoU_array, pixel_acc, mean_acc = testval(config, eval_dataloader, model, sv_dir='', sv_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7897b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mnea IoU: {:.3f}, mean Accuracy: {:.3f}, Pixel Accuracy: {:.3f}\".format(mean_IoU, mean_acc, pixel_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in trainid2label.items():\n",
    "    if key != config['IGNORE_LABEL'] and key != -1:\n",
    "        print(\"{} --- IoU: {:.2f}\".format(val.name, IoU_array[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
